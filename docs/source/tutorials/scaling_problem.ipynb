{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 05. Scaling Dependent Stepsize Problem\nIn some tests it has been noticed that the scaling of the\nimage has an influence on the regularized final result.\nIn this tutorial an example for the occurrence of such effects is shown.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A grey image is created and viewed once in area [0, 255] and once in area [0, 1].\nThe relation of the weighting between dataterm and regularization\nremains the same, but is adjusted in its absolute value too.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom recon.interfaces import Smoothing\nimport matplotlib.pyplot as plt\nfrom pylops import Gradient\n\n# build image\nsize, small_size = 256, 200\nscaled_image = np.reshape(np.array([(x/size) for x in range(size)]*size), (size, size))\nscaled_image[28:small_size+28, 28:small_size+28] = \\\n    np.reshape(np.array([(1-x/small_size)for x in range(small_size)]*small_size), (small_size, small_size))\nscaled_image /= np.max(scaled_image)\n\nassert np.all([0 <= np.min(scaled_image), np.max(scaled_image) == 1])\n\nunscaled_image = scaled_image * 255\n\nsigma = 0.2  # the percentage portion standard deviation for normal (Gaussian) distribution.\n\nnoise_scaled_image = scaled_image + np.random.normal(0, 0.2*np.max(scaled_image), size=(size, size))\nnoise_unscaled_image = unscaled_image + np.random.normal(0, 0.2*np.max(unscaled_image), size=(size, size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "...\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "weights = [(0.001, 0.2), (1, 0.2), (0.005, 1)]\n\nrows = ['{}'.format(row) for row in weights]\n\nf = plt.figure(figsize=(6, 3*len(weights)))\n\n\nfor i, weight in enumerate(weights):\n    tv_scaled_obj = Smoothing(domain_shape=scaled_image.shape, reg_mode='tv', lam=weight[0], alpha=weight[1], tau=0.3)\n    scaled_tv_solution = tv_scaled_obj.solve(scaled_image, max_iter=350)\n\n    tv_unscaled_obj = Smoothing(domain_shape=scaled_image.shape, reg_mode='tv', lam=weight[0], alpha=weight[1], tau=0.3)\n    unscaled_tv_solution = tv_unscaled_obj.solve(unscaled_image, max_iter=350)\n\n\n    f.add_subplot(3, 2, (i)*2+1)\n    plt.gray()\n    plt.axis('off')\n    plt.imshow(scaled_tv_solution)\n    plt.title(\"Scaled \" + str(weight))\n    f.add_subplot(3, 2, (i+1)*2)\n\n    plt.gray()\n    plt.imshow(unscaled_tv_solution)\n    plt.title(\"Unscaled \" + str(weight))\n    plt.axis('off')\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gradient Verification\nTo check there are no elemiation/condition things on the Gradient Operator:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grad = Gradient(dims=(size, size), edge=True, kind='backward')\nscaled_gradient = grad * noise_scaled_image.ravel()\nunscaled_gradient = grad * noise_unscaled_image.ravel()\n\nscaled_reconstruction = np.reshape(grad / scaled_gradient, (size, size))\nunscaled_reconstruction = np.reshape(grad / unscaled_gradient, (size, size))\n\nassert abs(np.linalg.norm(scaled_reconstruction - noise_scaled_image) -\n           np.linalg.norm((unscaled_reconstruction - noise_unscaled_image)/255) < 1)\n\nscaled_reconstruction = grad.H / (grad.H * scaled_gradient)\nunscaled_reconstruction = grad.H / (grad.H * unscaled_gradient)\n\nassert(abs(np.linalg.norm(scaled_reconstruction - scaled_gradient) -\n           np.linalg.norm((unscaled_reconstruction - unscaled_gradient)/255)) < 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conclusion\nThe Prox-Param tau is dependent on input scale.\nTherefore the calc method must be adapted in future versions.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}