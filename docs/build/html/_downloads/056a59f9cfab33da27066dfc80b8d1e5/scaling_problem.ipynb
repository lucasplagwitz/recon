{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 08. Scaling Dependent Stepsize Problem\nIn earlier tests it was noticed that the size of the weighting parameters\nhas an effect on the solution while keeping the ratio constant.\nMeanwhile the problem has been identified as a too small number of iterations.\nOverall, the default parameters have been adjusted, but in this example,\nwe will briefly show what the effect looks like.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A grey image is created and viewed in area [0, 1].\nThe relation of the weighting between dataterm and regularization\nremains the same, but is adjusted in its absolute value too.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom recon.interfaces import Smoothing\nimport matplotlib.pyplot as plt\n\nfrom recon.utils.images import two_smooth_squares\n\nscaled_image = two_smooth_squares(256, 200)\n\nsigma = 0.3  # the percentage portion standard deviation for normal (Gaussian) distribution.\n\nnoise_image = scaled_image + np.random.normal(0, sigma*np.max(scaled_image), size=scaled_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "...\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "weights = [(0.2, 0.2), (1, 1), (2, 2)]\n\nrows = ['{}'.format(row) for row in weights]\n\nf = plt.figure(figsize=(6, 3*len(weights)))\n\nfor i, weight in enumerate(weights):\n    tv_scaled_obj = Smoothing(domain_shape=scaled_image.shape,\n                              reg_mode='tv',\n                              lam=weight[0],\n                              alpha=weight[1],\n                              tau=\"calc\")\n    scaled_tv_solution = tv_scaled_obj.solve(noise_image, max_iter=5550, tol=1e-4)\n\n    tv_unscaled_obj = Smoothing(domain_shape=scaled_image.shape,\n                                reg_mode='tv',\n                                lam=weight[0],\n                                alpha=weight[1],\n                                tau=\"calc\")\n    unscaled_tv_solution = tv_unscaled_obj.solve(noise_image, max_iter=550, tol=1e-4)\n\n    f.add_subplot(3, 2, i*2+1)\n    plt.gray()\n    plt.axis('off')\n    plt.imshow(scaled_tv_solution)\n    plt.title(\"Long-Run: weight \" + str(weight))\n    f.add_subplot(3, 2, (i+1)*2)\n\n    plt.gray()\n    plt.imshow(unscaled_tv_solution)\n    plt.title(\"Short-Run: weight \" + str(weight))\n    plt.axis('off')\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conclusion\nBe careful with max_iter and tol parameter\nor with the interpretation of result if the number of iteration is too small.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}